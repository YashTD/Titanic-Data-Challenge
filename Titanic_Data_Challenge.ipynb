{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "from math import isnan\n",
    "import re\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.patches as mpatches\n",
    "plt.switch_backend('TkAgg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file_train_cross = \"train.csv\"\n",
    "df1 = pandas.read_csv(input_file_train_cross)\n",
    "#TODO: Handle Efficient regular shuffling\n",
    "df1 = df1.sample(frac=1, random_state=50).reset_index(drop=True)\n",
    "labels = df1.Survived\n",
    "\n",
    "input_file_test = \"test.csv\"\n",
    "test_df = pandas.read_csv(input_file_test)\n",
    "df1 = pandas.concat([df1, test_df])\n",
    "\n",
    "df2 = pandas.DataFrame()\n",
    "test_passenger_ids = test_df.PassengerId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first feature we will deal with is the Salutations of people on the ship. We will one-hot encode categories of salutations as defined by the Title_Dictionary dictionary in the interest of not adding 18 additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Salutations #1\n",
    "#df1['Salutation'] = df1.Name.map(lambda x: re.split(' ',re.split(',', x)[1].lstrip())[0])\n",
    "df1['Salutation'] = df1.Name.map(lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n",
    "#salutations = df1.Name.map(lambda x: re.split(' ',re.split(',', x)[1].lstrip())[0])\n",
    "salutations = df1.Name.map(lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n",
    "#for salutation in salutations.unique():\n",
    "#    salutation_key = 'salutation_'+salutation\n",
    "#    df2[salutation_key] = salutations.map(lambda x: 1 if x==salutation else 0)\n",
    "\n",
    "Title_Dictionary = {\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "                    }\n",
    "\n",
    "#salutations = salutations.map(Title_Dictionary)\n",
    "df2 = pandas.get_dummies(salutations, prefix = 'sal')\n",
    "#salutations_visualisation = pandas.concat([train_labels, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some passengers had multiple names, in all probability indicating maiden and married names, we parse this number into number_of_names. We then one-hot encode the ticket classes of the passengers and the locations they embarked the ship on. \n",
    "\n",
    "We then proceed to add age as an additional parameter and where the data is incomplete, we add the mean values of the age for the salutation of an individual. \n",
    "\n",
    "This is again followed by one-hot-encoding of the first letter of the cabins as this is indicative of the location of the cabin.\n",
    "\n",
    "Similar to the process for adding of age as a feature we then add the fare. Incomplete values are again determined by the mean values for a particular passenger class.\n",
    "\n",
    "Siblings and Spouses (Spice?), Parents and Children, and the Sex of the passengers are then added as features to df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Names PreProcess\n",
    "names = df1.Name.map(lambda x: re.split('\\(|\\)', x))\n",
    "first_name = names.map(lambda x: [y for y in x if y.replace(\" \",\"\") !=  ''])\n",
    "\n",
    "#Number of Words in Name\n",
    "#number_of_words = names.map(lambda x: len(re.split(' ',x[0])))\n",
    "#df1['number_of_words'] = number_of_words\n",
    "\n",
    "#No. of Names\n",
    "number_of_names = first_name.map(lambda x: len(x))\n",
    "df2['number_of_names'] = number_of_names\n",
    "\n",
    "#PClass\n",
    "for a_class in df1.Pclass.unique():\n",
    "    if(pandas.isnull(a_class) == False):\n",
    "        class_key = 'p_class_' + str(a_class)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    df2[class_key] = df1.Pclass.map(lambda x: 1 if x==a_class else 0)\n",
    "\n",
    "#Embarked\n",
    "for location in df1.Embarked.unique():\n",
    "    if(pandas.isnull(location) == False):\n",
    "        location_key = 'location_' + location\n",
    "        df2[location_key] = df1.Embarked.map(lambda x: 1 if x == location else 0)\n",
    "\n",
    "#Age\n",
    "title_mean_age = pandas.pivot_table(df1, values = 'Age', columns='Salutation', aggfunc='mean')\n",
    "df2['Age'] = df1.apply(lambda x: title_mean_age[x['Salutation']] if pandas.isnull(x['Age']) else x['Age'], axis = 1)\n",
    "\n",
    "#Cabin\n",
    "cabins = df1.Cabin.map(lambda x: str(x)[0] if len(str(x))>0 else 0)\n",
    "for cabin in cabins.unique():\n",
    "    if(pandas.isnull(cabin) == False):\n",
    "        cabin_key = 'cabin_' + cabin\n",
    "    else:\n",
    "        cabin_key = 'cabin_unknown'\n",
    "    df2[cabin_key] = cabins.map(lambda x: 1 if x==cabin else 0)\n",
    "\n",
    "#Fare\n",
    "pclass_mean_fare = pandas.pivot_table(df1, values='Fare', columns='Pclass', aggfunc='mean')\n",
    "df2['Fare'] = df1.apply(lambda x: pclass_mean_fare[x['Pclass']] if pandas.isnull(x['Fare']) else x['Fare'], axis =1)\n",
    "\n",
    "#SibSp and Parch\n",
    "df2['SibSp'] = df1.SibSp\n",
    "df2['Parch'] = df1.Parch\n",
    "\n",
    "#Sex\n",
    "df2['Sex'] = df1.Sex.map(lambda x: 0 if x =='male' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heat Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A heatmap to determine the correlation between the different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = df2.corr()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.matshow(corr)\n",
    "ax.set_title(\"Correlation between features\")\n",
    "plt.yticks(range(len(corr.columns)), corr.columns);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and Sex vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualisation_dataset = df2.iloc[:891, :]\n",
    "visualisation_labels = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the percentage of passengers who survived versus the age distinct for male and females. Similarly we plot the count survived vs age. \n",
    "\n",
    "We then plot the percentage survived against the various salutations, not our groupings but the original salutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blue_patch = mpatches.Patch(color='blue', label='Male')\n",
    "orange_patch = mpatches.Patch(color='orange', label='Female')\n",
    "binned_age, bins = pandas.cut(visualisation_dataset.Age, np.arange(0, 101, 10), retbins=True)\n",
    "d = {'age':binned_age, 'sex': visualisation_dataset.Sex, 'survived': visualisation_labels}\n",
    "age_sex = pandas.DataFrame(d)\n",
    "fig, [ax0, ax1] = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "#Percentage Survived vs Age\n",
    "d_male_mean = age_sex[age_sex.sex == 0].drop('sex', 1).groupby(['age']).mean().reset_index()\n",
    "d_female_mean = age_sex[age_sex.sex == 1].drop('sex', 1).groupby(['age']).mean().reset_index()\n",
    "rects1 = ax1.bar([0.6,2.6,4.6,6.6,8.6,10.6,12.6,14.6, 16.6, 18.6],  d_male_mean.survived, width=0.4, color='b', align='edge', label='Male')\n",
    "rects2 = ax1.bar([1,3,5,7,9,11,13,15, 17, 19],  d_female_mean.survived, width=0.4, color='orange', align='edge', label='Female')\n",
    "ax1.set_xlabel('Age Bins', color='white')\n",
    "ax1.set_ylabel('Percentage Survived', color='white')\n",
    "ax1.set_xticks([0,2,4,6,8,10,12,14,16, 18, 20])\n",
    "ax1.set_xticklabels(bins)\n",
    "ax1.legend()\n",
    "ax1.tick_params(colors='grey')\n",
    "ax1.set_title('Percentage Survived vs Age', color = 'white')\n",
    "ax1.set_facecolor('black')\n",
    "ax1.spines['left'].set_color('grey')\n",
    "ax1.spines['bottom'].set_color('grey')\n",
    "\n",
    "#Count Survived vs Age\n",
    "d_male_count = age_sex[age_sex.sex == 0].drop('sex', 1).groupby(['age']).count().reset_index()\n",
    "d_female_count = age_sex[age_sex.sex == 1].drop('sex', 1).groupby(['age']).count().reset_index()\n",
    "rects3 = ax0.bar([0.6,2.6,4.6,6.6,8.6,10.6,12.6,14.6, 16.6, 18.6],  d_male_count.survived, width=0.4, color='b', align='edge', label='Male')\n",
    "rects4 = ax0.bar([1,3,5,7,9,11,13,15, 17, 19],  d_female_count.survived, width=0.4, color='orange', align='edge', label='Female')\n",
    "ax0.set_xlabel('Age Bins', color='white')\n",
    "ax0.set_ylabel('Count Survived', color='white')\n",
    "#ax0.set_xticks([0,2,4,6,8,10,12,14,16, 18, 20])\n",
    "#ax0.set_xticklabels(bins)\n",
    "ax0.legend()\n",
    "ax0.tick_params(colors='grey')\n",
    "ax0.set_title('Count Survived vs Age', color='white')\n",
    "ax0.set_facecolor('black')\n",
    "ax0.spines['left'].set_color('grey')\n",
    "ax0.spines['bottom'].set_color('grey')\n",
    "\n",
    "#Percentage Survived vs Title\n",
    "fig1, ax = plt.subplots()\n",
    "salutation_list = visualisation_dataset.columns.values[np.core.defchararray.startswith(visualisation_dataset.columns.values.astype('U'), 'sal')]\n",
    "salutations_visualisation = pandas.concat([visualisation_dataset, visualisation_labels], axis=1)\n",
    "count_list =[]\n",
    "for individual_salutation in salutation_list:\n",
    "    count_list.append(salutations_visualisation.loc[salutations_visualisation[individual_salutation] == 1].Survived.mean())\n",
    "ax.bar(np.arange(1, len(count_list)*2 +1, 2), count_list)\n",
    "ax.set_xlabel('Salutations', color='white')\n",
    "ax.set_ylabel('Percentage Survived', color='white')\n",
    "ax.set_xticks(np.arange(1, len(count_list)*2 + 1, 2))\n",
    "sal_ticks = [x[4:] for x in salutation_list]\n",
    "#print np.apply_along_axis(m, 0, salutation_list)\n",
    "ax.set_xticklabels(sal_ticks, ha='left', rotation=-45)\n",
    "ax.tick_params(colors='grey', direction='out')\n",
    "ax.set_title('Percentage Survived vs Title')\n",
    "ax.set_facecolor('black')\n",
    "ax.spines['left'].set_color('grey')\n",
    "ax.spines['bottom'].set_color('grey')\n",
    "\n",
    "fig.set_facecolor('black')\n",
    "fig.set_tight_layout(True)\n",
    "fig1.set_facecolor('black')\n",
    "fig1.set_tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Feature and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = (df2 - df2.mean()) / (df2.max() - df2.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset_size = 691\n",
    "cv_dataset_size = 200\n",
    "train_dataset = df2.iloc[:train_dataset_size, :]\n",
    "train_labels = labels.iloc[:train_dataset_size]\n",
    "cv_dataset = df2.iloc[train_dataset_size:train_dataset_size+cv_dataset_size, :]\n",
    "cv_labels = labels.iloc[train_dataset_size:train_dataset_size+cv_dataset_size]\n",
    "test_dataset = df2.iloc[train_dataset_size+cv_dataset_size:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias vs Variance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values_of_lambda = np.sort(np.array([0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 5]))\n",
    "values_of_c = 1/values_of_lambda\n",
    "train_cost = []\n",
    "valid_cost = []\n",
    "other_vs_of_c = []\n",
    "for c in values_of_c:\n",
    "    logreg = LogisticRegression(C=c)\n",
    "    logreg.fit(train_dataset, train_labels)\n",
    "    train_cost.append(log_loss(train_labels, logreg.predict_proba(train_dataset)))\n",
    "    valid_cost.append(log_loss(cv_labels, logreg.predict_proba(cv_dataset)))\n",
    "    #train_cost.append(logreg.score(train_X, train_Y))\n",
    "    #valid_cost.append(logreg.score(valid_X, valid_Y))\n",
    "    #train_cost.append(_logistic_loss(logreg.coef_.ravel(), train_X.iloc[:391,:], train_Y.iloc[:391], c))\n",
    "    #valid_cost.append(_logistic_loss(logreg.coef_.ravel(), valid_X, valid_Y, c))\n",
    "plt.plot(values_of_lambda, train_cost, 'r--', label='Train Set')\n",
    "plt.plot(values_of_lambda, valid_cost, 'b--', label='CV Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = 1\n",
    "logreg = LogisticRegression(C=C)\n",
    "logreg.fit(train_dataset, train_labels)\n",
    "score = logreg.score(cv_dataset, cv_labels)\n",
    "print(\"The score is: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = logreg.predict(test_dataset)\n",
    "predictions_series = pandas.Series(predictions)\n",
    "results_df = pandas.DataFrame({'PassengerId' : test_passenger_ids,\n",
    "                               'Survived': predictions_series})\n",
    "results_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
